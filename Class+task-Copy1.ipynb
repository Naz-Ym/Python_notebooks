{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dmitriy Fedorov, Nazym Shakirkhozha\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 150 \n",
    "num_epochs = 20 \n",
    "hidden_size = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for a ,b in zip(y_train,np_utils.to_categorical(y_train, num_classes)):\n",
    "    '''print(a,b)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height, width, depth = 28, 28, 1 \n",
    "num_classes = 10 \n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "num_train = len(X_train)\n",
    "num_test = len(X_test) \n",
    "\n",
    "X_train = X_train.reshape(num_train, height * width)\n",
    "X_test = X_test.reshape(num_test, height * width) \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) \n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SP\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(height * width,)) \n",
    "hidden_1 = Dense(hidden_size, activation='relu')(inp) \n",
    "hidden_2 = Dense(hidden_size, activation='relu')(hidden_1) \n",
    "out = Dense(num_classes, activation='softmax')(hidden_2) \n",
    "model = Model(input=inp, output=out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SP\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 12s 226us/step - loss: 0.2423 - acc: 0.9294 - val_loss: 0.0981 - val_acc: 0.9725\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 11s 208us/step - loss: 0.0884 - acc: 0.9730 - val_loss: 0.0793 - val_acc: 0.9773\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 12s 217us/step - loss: 0.0555 - acc: 0.9830 - val_loss: 0.0730 - val_acc: 0.9788\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 13s 237us/step - loss: 0.0374 - acc: 0.9880 - val_loss: 0.0667 - val_acc: 0.9808\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 13s 238us/step - loss: 0.0280 - acc: 0.9909 - val_loss: 0.0606 - val_acc: 0.9827\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 12s 221us/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0791 - val_acc: 0.9780\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 12s 228us/step - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0655 - val_acc: 0.9828\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 13s 235us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0797 - val_acc: 0.9805\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 12s 222us/step - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0765 - val_acc: 0.9818\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 12s 227us/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0858 - val_acc: 0.9787\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 12s 225us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0976 - val_acc: 0.9765\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 12s 229us/step - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0863 - val_acc: 0.9818\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 12s 231us/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0954 - val_acc: 0.9812\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 12s 216us/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0977 - val_acc: 0.9807\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 12s 230us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0960 - val_acc: 0.9795\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 13s 237us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0886 - val_acc: 0.9827\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 13s 233us/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0826 - val_acc: 0.9822\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 13s 233us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0946 - val_acc: 0.9815\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 13s 235us/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.1121 - val_acc: 0.9805\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 13s 233us/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0950 - val_acc: 0.9820\n",
      "10000/10000 [==============================] - 1s 132us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10333385472477187, 0.9782]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, verbose=1, validation_split=0.1) \n",
    "model.evaluate(X_test, Y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.9857148e-19, 1.0173198e-12, 1.0000000e+00, 8.7105263e-14,\n",
       "        1.3083333e-28, 2.6714925e-19, 8.8728935e-18, 1.1553664e-21,\n",
       "        1.6746503e-18, 1.7729914e-26]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_test[1:2])\n",
    "model.predict(X_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xc34ea71208>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc34ea1e048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "two_d = (np.reshape(X_test[1:2], (28, 28)) * 255).astype(np.uint8)\n",
    "plt.imshow(two_d, interpolation='nearest',cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
